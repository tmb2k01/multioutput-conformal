{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4338c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from typing import Union\n",
    "\n",
    "from src.models.high_level_model import HighLevelModel\n",
    "from src.models.low_level_model import LowLevelModel\n",
    "from src.calibration.calibration import calibration\n",
    "from src.data.multi_output_dataset import MultiOutputDataModule\n",
    "from src.models.model_utils import convert_multitask_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8d29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDC_COLOR = 12\n",
    "MDC_TYPE = 11\n",
    "MDC_TASK_NUM_CLASSES = [MDC_COLOR, MDC_TYPE]\n",
    "root_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e823e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numpy_to_native(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_to_native(x) for x in obj]\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ed3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(\n",
    "    model: Union[HighLevelModel, LowLevelModel],\n",
    "    datamodule: MultiOutputDataModule,\n",
    "    load_preds=False,\n",
    "):\n",
    "    high_level = isinstance(model, HighLevelModel)\n",
    "    high_level_string = \"high\" if high_level else \"low\"\n",
    "    if load_preds:\n",
    "        calib_preds = np.load(f\"./models/mdc-{high_level_string}-model-calibpreds.npz\")\n",
    "        calib_preds = [calib_preds[key] for key in calib_preds.files]\n",
    "        if not high_level:\n",
    "            calib_preds = np.array(calib_preds)\n",
    "\n",
    "    else:\n",
    "        model.eval()\n",
    "        trainer = pl.Trainer(accelerator=\"gpu\")\n",
    "        calib_preds = trainer.predict(model, dataloaders=datamodule.calib_dataloader())\n",
    "        if high_level:\n",
    "            calib_preds = convert_multitask_preds(calib_preds)\n",
    "        else:\n",
    "            calib_preds = np.concatenate(calib_preds, axis=0)\n",
    "            calib_preds = np.array(calib_preds)\n",
    "        np.savez(f\"./models/mdc-{high_level_string}-model-calibpreds\", *calib_preds)\n",
    "\n",
    "    true_labels = np.stack(\n",
    "        [labels for _, labels in datamodule.datasets[\"calib\"]], axis=1\n",
    "    )\n",
    "    if not high_level:\n",
    "        multiplier = np.array(\n",
    "            [\n",
    "                math.prod(datamodule.task_num_classes[i + 1 :])\n",
    "                for i in range(len(datamodule.task_num_classes))\n",
    "            ]\n",
    "        )\n",
    "        true_labels = np.array(true_labels * multiplier[:, None]).sum(axis=0)\n",
    "\n",
    "    q_hats = calibration(\n",
    "        calib_preds,\n",
    "        true_labels,\n",
    "        high_level,\n",
    "    )\n",
    "\n",
    "    with open(f\"models/mdc-{high_level_string}-level-calibration.json\", \"w\") as f:\n",
    "        json.dump(convert_numpy_to_native(q_hats), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0ce9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HighLevelModel.load_from_checkpoint(\n",
    "    \"models/mdc-high-level-model.ckpt\",\n",
    "    map_location=\"cpu\",\n",
    "    task_num_classes=MDC_TASK_NUM_CLASSES,\n",
    ")\n",
    "datamodule = MultiOutputDataModule(\n",
    "    root_dir=root_dir,\n",
    "    task_num_classes=MDC_TASK_NUM_CLASSES,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41b2dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/tmb2k01/masters-thesis/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 76/76 [00:11<00:00,  6.40it/s]\n"
     ]
    }
   ],
   "source": [
    "calibrate_model(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    "    load_preds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d50cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LowLevelModel.load_from_checkpoint(\n",
    "    \"models/mdc-low-level-model.ckpt\",\n",
    "    map_location=\"cpu\",\n",
    "    task_num_classes=MDC_TASK_NUM_CLASSES,\n",
    ")\n",
    "datamodule = MultiOutputDataModule(\n",
    "    root_dir=root_dir,\n",
    "    task_num_classes=MDC_TASK_NUM_CLASSES,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4548c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 76/76 [00:11<00:00,  6.57it/s]\n"
     ]
    }
   ],
   "source": [
    "calibrate_model(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    "    load_preds=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
